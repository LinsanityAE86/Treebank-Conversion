[Run]
is_test = 0
is_train = 1
device-x = gpu
device = cuda:0
dict_dir = ./
word_freq_cutoff = 1
model_dir = ./
ext_word_emb_full_path = ../data/giga.bin
ext_word_dict_full_path = ../data/extwords.txt
inst_num_max = -1
max_bucket_num = 80
sent_num_one_batch = 50
word_num_one_batch = 200
is_shared_lstm = 1
is_gate_lstm = 0
is_diff_loss = 1
is_domain_emb = 1
is_adversary = 1
is_multi = 1
is_charlstm = 1

[Test]
model_eval_num = 0

[Train]
data_dir = ../data/ud
train_files = ../data/ud/ud-double-train.conll:../data/vndt/vndt-train.txt
dev_files = %(data_dir)s/ud-double-dev.conll
test_files = %(data_dir)s/ud-double-test.conll
unlabel_train_files = ../data/unlabal/vi-unlabel-train.txt
is_dictionary_exist = 1
train_max_eval_num = 1000
save_model_after_eval_num = 1
train_stop_after_eval_num_no_improve = 100
eval_every_update_step_num = 49

[Network]
lstm_layer_num = 3
word_emb_dim = 100
tag_emb_dim = 100
domain_emb_dim = 8
domain_size = 4
emb_dropout_ratio = 0.33
lstm_hidden_dim = 300
lstm_input_dropout_ratio = 0.33
lstm_hidden_dropout_ratio_for_next_timestamp = 0.33
mlp_output_dim_arc = 500
mlp_output_dim_rel = 100
mlp_input_dropout_ratio = 0.33
mlp_output_dropout_ratio = 0.33
src_label_emb_dim = 50
src_label_dropout_ratio = 0.33
inside_treelstm_dropout_ratio = 0
outside_treelstm_dropout_ratio = 0.5
treelstm_hidden_dim = 100

[Optimizer]
learning_rate = 2e-3
decay = .75
decay_steps = 5000
beta_1 = .9
beta_2 = .9
epsilon = 1e-12
clip = 5.0
adversary_lambda_loss = 0.001
diff_bate_loss = 0.01

